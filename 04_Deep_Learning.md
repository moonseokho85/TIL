# Deep Learning



## [전통적인 머신러닝] 을 넘어 딥러닝으로

### 관계도

[NVIDIA 공식 블로그](https://blogs.nvidia.co.kr/2016/08/03/difference_ai_learning_machinelearning/)

![image-20191227111558246](C:\Users\mseok\AppData\Roaming\Typora\typora-user-images\image-20191227111558246.png)

**인공 지능**이 가장 큰 원이고, 그 다음이 **머신 러닝**이며, 현재의 인공지능 붐을 주도하는 **딥 러닝**이 가장 작은 원이라 할 수 있죠.



### 인공지능 기술의 탄생 및 성장



인공 지능이라는 개념은 1956년 미국 다트머스 대학에 있던 존 매카시 교수가 개최한 다트머스 회의에서 처음 등장했으며, 최근 몇 년 사이 폭발적으로 성장하고 있는 중입니다. 특히 2015년 이후 신속하고 강력한 병렬 처리 성능을 제공하는 **GPU**의 도입으로 더욱 가속화되고 있습니다. 갈수록 폭발적으로 늘어나고 있는 저장 용량과 이미지, 텍스트, 매핑 데이터 등 모든 영역의 데이터가 범람하게 된 ‘빅데이터’ 시대의 도래도 이러한 성장세에 큰 영향을 미쳤습니다.



### 딥 러닝 : 완전한 머신 러닝을 실현하는 기술



![image-20191227124049812](C:\Users\mseok\AppData\Roaming\Typora\typora-user-images\image-20191227124049812.png)

초기 머신 러닝 연구자들이 만들어 낸 또 다른 알고리즘인 인공 신경망 (artificial neural network) 에 영감을 준 것은 인간의 뇌가 지닌 생물학적 특성, 특히 뉴런의 연결 구조였습니다. 그러나 물리적으로 근접한 어떤 뉴런이든 상호 연결이 가능한 뇌와는 달리, 인공 신경망은 레이어 연결 및 데이터 전파 방향이 일정합니다.



#### <사람 뇌와 인공신경망의 차이점>

| 구분      | 뇌       | 인공 신경망 |
| --------- | -------- | ----------- |
| 전파 방향 | 상호연결 | 일정        |



![image-20191227124250555](C:\Users\mseok\AppData\Roaming\Typora\typora-user-images\image-20191227124250555.png)



**예를 들어**, 이미지를 수많은 타일로 잘라 신경망의 첫 번째 레이어에 입력하면, 그 뉴런들은 데이터를 다음 레이어로 전달하는 과정을 마지막 레이어에서 최종 출력이 생성될 때까지 반복합니다. 그리고 각 뉴런에는 수행하는 작업을 기준으로 입력의 정확도를 나타내는 가중치가 할당되며, 그 후 가중치를 모두 합산해 최종 출력이 결정됩니다.

정지 표지판의 경우, 팔각형 모양, 붉은 색상, 표시 문자, 크기, 움직임 여부 등 그 이미지의 특성을 잘게 잘려 뉴런에서 '검사'되며, 신경망의 임무는 이것이 정지 표지판인지 여부를 식별하는 것입니다. 여기서는 충분한 데이터를 바탕으로 가중치에 따라 결과를 예측하는 **'확률벡터 (Probability Vector)'**가 활용됩니다.

> **확률벡터 (Probability Vector)** : 원소가 모두 확률변수인 벡터

딥 러닝은 인공신경망에서 발전한 형태의 인공 지능으로, 뇌의 뉴런과 유사한 정보 입출력 계층을 활용해 데이터를 학습한다. 그러나 기본적인 신경망조차 굉장한 양의 연산을 필요로 하는 탓에 딥 러닝의 상용화는 초기부터 난관에 부딪혔습니다. 그럼에도 토론토대의 제프리 힌튼(Geoffrey Hinton) 교수 연구팀과 같은 일부 기관에서는 연구를 지속했고, 슈퍼컴퓨터를 기반으로 딥 러닝 개념을 증명하는 알고리즘을 병렬화하는데 성공했습니다. 그리고 병렬 연산에 최적화된 GPU의 등장은 신경망의 연산 속도를 획기적으로 가속하며 진정한 딥 러닝 기반 인공 지능의 등장을 불러왔습니다.

신경망 네트워크는 ‘학습’ 과정에서 수많은 오답을 낼 가능성이 큽니다. 정지 표지판의 예로 돌아가서, 기상 상태, 밤낮의 변화에 관계 없이 항상 정답을 낼 수 있을 정도로 정밀하게 뉴런 입력의 가중치를 조정하려면 수백, 수천, 어쩌면 수백만 개의 이미지를 학습해야 할지도 모르죠. 이 정도 수준의 정확도에 이르러서야 신경망이 정지 표지판을 제대로 학습했다고 볼 수 있습니다.

2012년, 구글과 스탠퍼드대 앤드류 응(Andrew NG) 교수는 1만6,000개의 컴퓨터로 약 10억 개 이상의 신경망으로 이뤄진 ‘심층신경망(Deep Neural Network)’을 구현했습니다. 이를 통해 유튜브에서 이미지 1,000만 개를 뽑아 분석한 뒤, 컴퓨터가 사람과 고양이 사진을 분류하도록 하는데 성공했습니다. 컴퓨터가 영상에 나온 고양이의 형태와 생김새를 인식하고 판단하는 과정을 스스로 학습하게 한 것이죠.

딥 러닝으로 훈련된 시스템의 이미지 인식 능력은 이미 인간을 앞서고 있습니다. 이 밖에도 딥 러닝의 영역에는 혈액의 암세포, MRI 스캔에서의 종양 식별 능력 등이 포함됩니다. 구글의 알파고는 바둑의 기초를 배우고, 자신과 같은 AI를 상대로 반복적으로 대국을 벌이는 과정에서 그 신경망을 더욱 강화해 나갔습니다.



### 딥 러닝으로 밝은 미래를 꿈꾸는 인공 지능



딥 러닝의 등장으로 인해 머신 러닝의 실용성은 강화됐고, 인공 지능의 영역은 확장되었습니다. 딥 러닝은 컴퓨터 시스템을 통해 지원 가능한 모든 방식으로 작업을 세분화합니다. 운전자 없는 자동차, 더 나은 예방 의학, 더 정확한 영화 추천 등 딥 러닝 기반의 기술들은 우리 일상에서 이미 사용되고 있거나, 실용화를 앞두고 있습니다. 딥 러닝은 공상과학에서 등장했던 일반 AI를 실현할 수 있는 잠재력을 지닌 인공 지능의 현재이자, 미래로 평가 받고 있습니다.



### Perceptron 구조

![image-20191227131001838](C:\Users\mseok\AppData\Roaming\Typora\typora-user-images\image-20191227131001838.png)

각 뉴런에는 입력신호를 가공하여 출력을 도출하기 위해서 활성화 함수 (activation function)가 역할을 하는데, 활성화 함수에는 계단 함수, 시그모이드 함수, Rectified Linear Unit 함수 등이 있습니다. 



### Deep Neural Network 구조

![image-20191227131349435](C:\Users\mseok\AppData\Roaming\Typora\typora-user-images\image-20191227131349435.png)

