{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 읽기\n",
    "img = cv2.imread(\"img/paper.jpg\")\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그레이 스케일로 변환을 합니다. -> 흑백 이미지로 바꾸는 이유는 findContour가 흑백이미지 또는 이진화된 이미지만 적용할 수 있기 때문이다.\n",
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('imgray', imgray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가우시안 블러로 노이즈를 제거합니다.\n",
    "blur = cv2.GaussianBlur(imgray, (5, 5), 0)\n",
    "\n",
    "cv2.imshow('blur', blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적응형 스레스홀드로 흑백 이미지를 이진화 이미지로 바꿔줍니다.\n",
    "th = cv2.adaptiveThreshold(imgray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 3)\n",
    "\n",
    "cv2.imshow('thresh', th)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(th, 50, 260)\n",
    "\n",
    "cv2.imshow('edges', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케니 엣지로 경계를 검출합니다.\n",
    "edges = cv2.Canny(blur, 50, 260)\n",
    "\n",
    "cv2.imshow('edges2', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of contours:  1\n",
      "hierarchy:  [[[-1 -1 -1 -1]]]\n"
     ]
    }
   ],
   "source": [
    "# 모든 컨투어들을 찾아냅니다.\n",
    "_, contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL,  cv2.CHAIN_APPROX_SIMPLE) # 모든 계층 정보를 트리 구조로 제공/컨투어 꼭지점 좌표만 이용\n",
    "\n",
    "# (확인) 컨투어 갯수와 계층 트리를 출력합니다.\n",
    "print(\"number of contours: \", len(contours))\n",
    "print(\"hierarchy: \", hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big contour:  [[[ 81  75]]\n",
      "\n",
      " [[ 80  76]]\n",
      "\n",
      " [[ 48  76]]\n",
      "\n",
      " [[ 48 103]]\n",
      "\n",
      " [[ 47 104]]\n",
      "\n",
      " [[ 47 137]]\n",
      "\n",
      " [[ 46 138]]\n",
      "\n",
      " [[ 46 162]]\n",
      "\n",
      " [[ 45 163]]\n",
      "\n",
      " [[ 45 195]]\n",
      "\n",
      " [[ 44 196]]\n",
      "\n",
      " [[ 44 228]]\n",
      "\n",
      " [[ 93 228]]\n",
      "\n",
      " [[ 94 227]]\n",
      "\n",
      " [[165 227]]\n",
      "\n",
      " [[165 208]]\n",
      "\n",
      " [[164 207]]\n",
      "\n",
      " [[164 192]]\n",
      "\n",
      " [[163 191]]\n",
      "\n",
      " [[163 170]]\n",
      "\n",
      " [[162 169]]\n",
      "\n",
      " [[162 148]]\n",
      "\n",
      " [[161 147]]\n",
      "\n",
      " [[161 118]]\n",
      "\n",
      " [[160 117]]\n",
      "\n",
      " [[160 102]]\n",
      "\n",
      " [[159 101]]\n",
      "\n",
      " [[159  79]]\n",
      "\n",
      " [[158  78]]\n",
      "\n",
      " [[158  77]]\n",
      "\n",
      " [[150  77]]\n",
      "\n",
      " [[149  76]]\n",
      "\n",
      " [[ 87  76]]\n",
      "\n",
      " [[ 86  75]]\n",
      "\n",
      " [[ 85  75]]\n",
      "\n",
      " [[ 84  76]]\n",
      "\n",
      " [[ 83  76]]\n",
      "\n",
      " [[ 82  75]]]\n"
     ]
    }
   ],
   "source": [
    "# (hint) 컨투어들 중에 영역 크기 순으로 정렬합니다.\n",
    "contour = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
    "\n",
    "print(\"Big contour: \", contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx:  [[[ 48  76]]\n",
      "\n",
      " [[ 44 228]]\n",
      "\n",
      " [[165 227]]\n",
      "\n",
      " [[158  77]]]\n"
     ]
    }
   ],
   "source": [
    "# approxPolyDP 함수를 사용하여 꼭지점의 좌표를 추출합니다. \n",
    "approx = cv2.approxPolyDP(contour, 0.01*cv2.arcLength(contour, True), True)\n",
    "\n",
    "print(\"Approx: \", approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized approx:  [[ 48  76]\n",
      " [ 44 228]\n",
      " [165 227]\n",
      " [158  77]]\n"
     ]
    }
   ],
   "source": [
    "# approx의 사이즈를 다시 조정합니다.\n",
    "approx = np.array(approx)\n",
    "resized_approx = np.resize(approx, (4,2))\n",
    "print('Resized approx: ', resized_approx)\n",
    "\n",
    "# Pos를 이용하여 x, y 좌표 분해\n",
    "# x=pos.reshape(8,1)[0::2]\n",
    "# y=pos.reshape(8,1)[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 사진의 가로 길이:  259\n",
      "원본 사진의 세로 길이:  194\n"
     ]
    }
   ],
   "source": [
    "# 원본 사진의 크기를 전역변수 rows, cols에 담아줍니다.\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "print(\"원본 사진의 가로 길이: \", rows)\n",
    "print(\"원본 사진의 세로 길이: \", cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원근 변환을 해줍니다.\n",
    "pts1 = np.float32([resized_approx[0], resized_approx[1], resized_approx[2], resized_approx[3]])\n",
    "\n",
    "# pts1 = np.float32([ [x[0],y[0]], [x[1],y[1]], [x[2],y[2]], [x[3],y[3]] ])\n",
    "\n",
    "pts2 = np.float32([[0,0], [0, rows], [cols, rows], [cols, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원근 변환 행렬 계산\n",
    "mtrx = cv2.getPerspectiveTransform(pts1, pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원근 변환 적용\n",
    "dst = cv2.warpPerspective(img, mtrx, (cols, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새 창으로 결과를 출력합니다.\n",
    "cv2.imshow('result', dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# img = cv2.imread(\"img/paper.jpg\")\n",
    "# draw = img.copy()\n",
    "\n",
    "# # 그레이스 스케일 변환 및 케니 엣지\n",
    "# imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# th = cv2.adaptiveThreshold(imgray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 3)\n",
    "# blur = cv2.GaussianBlur(th, (5, 5), 0)\n",
    "# edges = cv2.Canny(blur, 50, 260)\n",
    "\n",
    "# # 컨투어 찾기\n",
    "# _, cnts, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL,  cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # 모든 컨투어 그리기\n",
    "\n",
    "\n",
    "\n",
    "# # 컨투어들 중에 영역 크기 순으로 정렬\n",
    "# cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "# for c in cnts:\n",
    "#     # 영역이 가장 큰 컨투어 부터 근사 컨투어 단순화\n",
    "#     peri = cv2.arcLength(c, True)   # 둘레 길이\n",
    "#     # 둘레 길이의 0.02 근사값으로 근사화\n",
    "#     vertices = cv2.approxPolyDP(c, 0.02 * peri, True) \n",
    "#     if len(vertices) == 4: # 근사한 꼭지점이 4개면 중지\n",
    "#         break\n",
    "# pts = vertices.reshape(4, 2) # N x 1 x 2 배열을 4 x 2크기로 조정\n",
    "# for x,y in pts:\n",
    "#     cv2.circle(draw, (x,y), 10, (0,255,0), -1) # 좌표에 초록색 동그라미 표시\n",
    "# merged = np.hstack((img, draw))\n",
    "\n",
    "# # 좌표 4개 중 상하좌우 찾기 ---② \n",
    "# sm = pts.sum(axis=1)                 # 4쌍의 좌표 각각 x+y 계산\n",
    "# diff = np.diff(pts, axis = 1)       # 4쌍의 좌표 각각 x-y 계산\n",
    "\n",
    "# topLeft = pts[np.argmin(sm)]         # x+y가 가장 작은 값이 좌상단 좌표\n",
    "# bottomRight = pts[np.argmax(sm)]     # x+y가 가장 큰 값이 좌상단 좌표\n",
    "# topRight = pts[np.argmin(diff)]     # x-y가 가장 작은 값이 우상단 좌표\n",
    "# bottomLeft = pts[np.argmax(diff)]   # x-y가 가장 큰 값이 좌하단 좌표\n",
    "\n",
    "# # 변환 전 4개 좌표 \n",
    "# pts1 = np.float32([topLeft, topRight, bottomRight , bottomLeft])\n",
    "\n",
    "# # 변환 후 영상에 사용할 서류의 폭과 높이 계산 ---③ \n",
    "# w1 = abs(bottomRight[0] - bottomLeft[0])    # 상단 좌우 좌표간의 거리\n",
    "# w2 =           # 하당 좌우 좌표간의 거리\n",
    "# h1 =       # 우측 상하 좌표간의 거리\n",
    "# h2 =         # 좌측 상하 좌표간의 거리\n",
    "# width =                       # 두 좌우 거리간의 최대값이 서류의 폭\n",
    "# height =                      # 두 상하 거리간의 최대값이 서류의 높이\n",
    "\n",
    "# # 변환 후 4개 좌표\n",
    "# pts2 = \n",
    "\n",
    "# # 변환 행렬 계산 \n",
    "# mtrx = \n",
    "\n",
    "# # 원근 변환 적용\n",
    "# result = \n",
    "\n",
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "# plt.imshow(cv2.cvtColor(edged, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "# plt.imshow(cv2.cvtColor(draw, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "# plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
