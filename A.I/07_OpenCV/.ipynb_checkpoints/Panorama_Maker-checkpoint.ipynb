{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: 57/190, min: 12.00, max: 76.00, thresh: 31.20\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 사진을 불러옵니다.\n",
    "img1 = cv2.imread('img/restaurant1.jpg')\n",
    "img2 = cv2.imread('img/restaurant2.jpg')\n",
    "\n",
    "# 흑백이미지로 만들어 줍니다.\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 검출기 ORB로 서술자 추출합니다. \n",
    "detector = cv2.ORB_create()\n",
    "\n",
    "# output:\n",
    "# detector:  <ORB 000001E6A7115C50>\n",
    "\n",
    "# 검출기로 검출을 합니다.\n",
    "keypoint1, descriptor1 = detector.detectAndCompute(gray2, None)\n",
    "\n",
    "    # keypoints, descriptors = detector.detectAndCompute(image, mask) : 키 포인트 검출과 특징 descriptor 계산을 한번에 수행\n",
    "    # descriptor: 특징점의 주변 특성을 이용해 해당 특징점을 표현하는 벡터를 만들어 이미지에서 같은 특징점을 매칭하거나 추출 할 때 사용합니다.\n",
    "\n",
    "# output:\n",
    "\n",
    "# kp1: [<KeyPoint 000001E6A6D04330>, <KeyPoint 000001E6A734BB70>, <KeyPoint 000001E6A734B480>, ...]\n",
    "\n",
    "# desc1:  [[ 86  39 174 ... 103  37 242]\n",
    "#  [164  38 255 ... 225  71 228]\n",
    "#  [  9 249  49 ...  10 195 253]\n",
    "#  ...\n",
    "#  [ 80 188 190 ...  80 167  75]\n",
    "#  [168 168 185 ...   8 198 170]\n",
    "#  [ 68 187 159 ...   9 129  18]]\n",
    "\n",
    "keypoint2, descriptor2 = detector.detectAndCompute(gray1, None)\n",
    "\n",
    "# output\n",
    "# ...\n",
    "\n",
    "# BF-Hamming으로 매칭합니다. (BFMatcher 생성, Hamming 거리, 상호 체크)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # BFMatcher:\n",
    "    # BFMatcher는 특징 디스크립터를 전수 조사 하므로 매칭에 사용할 영상이 큰 경우 속도가 느려질때 사용합니다. \n",
    "    # BF는 Brute Force의 약자입니다. 가능한 모든 경우에 대해 다 계산해본 후 최적의 결과를 반환하는 알고리즘입니다.\n",
    "    \n",
    "    # cv2.BFMatcher( ) 함수는 image 1의 descriptor1과 가장 유사도가 높은 image 2의 descriptor를 찾기 위해 \n",
    "    # M개의 descriptor를 대상으로 거리를 모두 구한 다음에 가장 짧은 거리를 갖는 image 2의 descriptor를 찾는다.\n",
    "    # cv2.BFMatcher( )는 매칭된 descriptor들의 index와 유사도를 반환한다.\n",
    "    \n",
    "    #\n",
    "\n",
    "# output\n",
    "# matcher:  <BFMatcher 000001E6A7130E90>\n",
    "\n",
    "matches = matcher.match(descriptor1, descriptor2)\n",
    "\n",
    "# output: [<DMatch 000001E6A7115ED0>, <DMatch 000001E6A7115DD0>, <DMatch 000001E6A7115BF0>, ...]\n",
    "\n",
    "# 매칭 결과를 거리기준 오름차순으로 정렬\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "\n",
    "# output: [<DMatch 000001E6A7130DB0>, <DMatch 000001E6A71635B0>, <DMatch 000001E6A00F2830>, ...]\n",
    "\n",
    "# 최소 거리 값과 최대 거리 값 확보 \n",
    "min_dist, max_dist = matches[0].distance, matches[-1].distance\n",
    "\n",
    "# output:\n",
    "# min_dist:  12.0\n",
    "# max_dist:  90.0\n",
    "\n",
    "# 최소 거리의 30% 지점을 임계점으로 설정 \n",
    "ratio = 0.3\n",
    "good_thresh = (max_dist - min_dist) * ratio + min_dist\n",
    "\n",
    "# output:\n",
    "# good_thresh:  35.4\n",
    "\n",
    "# 임계점 보다 작은 매칭점만 좋은 매칭점으로 분류 \n",
    "# m.distance 매칭객체의 거리 공통함수부분참조  \n",
    "good_matches = [m for m in matches if m.distance < good_thresh]\n",
    "\n",
    "    # distance: descriptor1[0]와 매칭된 descriptor2의 descriptor 사이의 거리( = 유사도 )값이다.\n",
    "\n",
    "# output:\n",
    "# [<DMatch 000001A204E78430>, <DMatch 000001A204E3B570>, <DMatch 000001A204E78ED0>, <DMatch 000001A204E3B5B0>, <DMatch 000001A204E3B6B0>, <DMatch 000001A204E3B730>, <DMatch 000001A204E3B150>, <DMatch 000001A204E78370>, <DMatch 000001A204E78830>, <DMatch 000001A204E78A50>, <DMatch 000001A204E3B3D0>, <DMatch 000001A204E3B4D0>, <DMatch 000001A204E3B550>, <DMatch 000001A204E787B0>, <DMatch 000001A204E78E70>, <DMatch 000001A204E78F70>, <DMatch 000001A204E3B370>, <DMatch 000001A204E3B670>, <DMatch 000001A204E78190>, <DMatch 000001A204E78AD0>, <DMatch 000001A204E78BD0>, <DMatch 000001A204E3B790>, <DMatch 000001A204E78A30>, <DMatch 000001A204E78B70>, <DMatch 000001A204E78C10>, <DMatch 000001A204E3B770>, <DMatch 000001A204E78270>, <DMatch 000001A204E3B2F0>, <DMatch 000001A204E3B3B0>, <DMatch 000001A204E781B0>, <DMatch 000001A204E78B10>, <DMatch 000001A204E78E10>, <DMatch 000001A204E78E30>, <DMatch 000001A204E78F30>, <DMatch 000001A204E3B630>, <DMatch 000001A204E78130>, <DMatch 000001A204E78250>, <DMatch 000001A204E78DF0>, <DMatch 000001A204E78E90>, <DMatch 000001A204E3B750>, <DMatch 000001A204E78550>, <DMatch 000001A204E78C50>, <DMatch 000001A204E3B130>, <DMatch 000001A204E3B1D0>, <DMatch 000001A204E3B650>, <DMatch 000001A204E78C30>, <DMatch 000001A204E3B210>, <DMatch 000001A204E783D0>, <DMatch 000001A204E783F0>, <DMatch 000001A204E78510>, <DMatch 000001A204E78970>, <DMatch 000001A204E789D0>, <DMatch 000001A204E789F0>, <DMatch 000001A204E78A70>, <DMatch 000001A204E78DD0>, <DMatch 000001A204E78210>, <DMatch 000001A204E78BB0>]\n",
    "\n",
    "print('matches: %d/%d, min: %.2f, max: %.2f, thresh: %.2f' %(len(good_matches),len(matches), min_dist, max_dist, good_thresh))\n",
    "# output: matches: 57/190, min: 12.00, max: 76.00, thresh: 31.20\n",
    "\n",
    "# 좋은 매칭점의 queryIdx로 원본 영상의 좌표 구하기\n",
    "src_pts = np.float32([ keypoint1[m.queryIdx].pt for m in good_matches ])\n",
    "\n",
    "    # queryIdx: 기준이 되는 descriptor 및 keypoint의 index이다. matches[0]는 desA[0]를 기준으로 삼기 때문에 matches[0].queryIdx = 0 이다.\n",
    "\n",
    "# output:\n",
    "\n",
    "# [[180.       126.      ]\n",
    "#  [161.24318  194.08902 ]\n",
    "#  [ 93.31201  224.64001 ]\n",
    "#  [182.14508  143.32727 ]\n",
    "#  [128.39734  191.10303 ]\n",
    "#  [161.24318  193.49182 ]\n",
    "#  [163.81442  217.72803 ]\n",
    "#  [163.       214.      ]\n",
    "#  [ 93.600006 222.00002 ]\n",
    "#  [ 93.600006 221.76001 ]\n",
    "#  [144.3226   184.13573 ]\n",
    "#  [ 92.06786  223.94885 ]\n",
    "#  [184.13573  236.39046 ]\n",
    "#  [135.6      219.6     ]\n",
    "#  [ 55.296005 229.82402 ]\n",
    "#  [155.52002  190.08002 ]\n",
    "#  [129.39267  191.6007  ]\n",
    "#  [128.39734  214.9909  ]\n",
    "#  [107.       319.      ]\n",
    "#  [162.72     192.96    ]\n",
    "#  [174.24      96.48    ]\n",
    "#  [128.99455  197.075   ]\n",
    "#  [155.52     190.08    ]\n",
    "#  [128.16     216.00002 ]\n",
    "#  [ 56.160004 228.96    ]\n",
    "#  [161.24318  218.5741  ]\n",
    "#  [162.       211.      ]\n",
    "#  [ 93.31201  223.94884 ]\n",
    "#  [129.39267  216.48389 ]\n",
    "#  [167.       216.      ]\n",
    "#  [ 87.840004 260.64    ]\n",
    "#  [184.89601  236.73602 ]\n",
    "#  [ 60.480007 255.74402 ]\n",
    "#  [134.78401  188.35202 ]\n",
    "#  [104.50947  304.57043 ]\n",
    "#  [ 66.       215.      ]\n",
    "#  [154.       188.      ]\n",
    "#  [164.16002  210.81602 ]\n",
    "#  [148.60802  184.89601 ]\n",
    "#  [128.99455  214.9909  ]\n",
    "#  [129.6      190.8     ]\n",
    "#  [180.        99.36    ]\n",
    "#  [128.56322  215.65443 ]\n",
    "#  [178.32962   95.38561 ]\n",
    "#  [161.24318  217.9769  ]\n",
    "#  [164.16     211.68001 ]\n",
    "#  [161.74083  192.84483 ]\n",
    "#  [128.       219.      ]\n",
    "#  [164.       194.      ]\n",
    "#  [134.40001  189.6     ]\n",
    "#  [171.36     217.44    ]\n",
    "#  [126.72     210.24    ]\n",
    "#  [135.36     188.64001 ]\n",
    "#  [185.76001  237.6     ]\n",
    "#  [ 88.128006 271.29602 ]\n",
    "#  [136.       190.      ]\n",
    "#  [ 89.28001  269.28    ]]\n",
    "\n",
    "# 좋은 매칭점의 trainIdx로 대상 영상의 좌표 구하기\n",
    "dst_pts = np.float32([ keypoint2[m.trainIdx].pt for m in good_matches ])\n",
    "\n",
    "    #  trainIdx: descriptor1[0]과 매칭된 image 2, descriptor의 index에 해당한다.\n",
    "\n",
    "# output:\n",
    "# [[484.        94.      ]\n",
    "#  [468.79962  167.21515 ]\n",
    "#  [406.08002  207.36002 ]\n",
    "#  [489.7015   110.48144 ]\n",
    "#  [435.9538   173.18712 ]\n",
    "#  [469.39682  168.40955 ]\n",
    "#  [474.85446  190.77122 ]\n",
    "#  [474.       187.      ]\n",
    "#  [407.       207.      ]\n",
    "#  [406.80002  207.6     ]\n",
    "#  [450.38602  161.74084 ]\n",
    "#  [406.42566  207.36003 ]\n",
    "#  [500.15244  209.01894 ]\n",
    "#  [445.2      196.8     ]\n",
    "#  [375.84003  216.00002 ]\n",
    "#  [463.10403  164.16002 ]\n",
    "#  [437.94443  171.69412 ]\n",
    "#  [438.93976  194.08902 ]\n",
    "#  [435.       294.      ]\n",
    "#  [470.88     167.04001 ]\n",
    "#  [473.76      66.240005]\n",
    "#  [437.1482   175.57591 ]\n",
    "#  [463.68002  164.16    ]\n",
    "#  [437.76     194.40001 ]\n",
    "#  [375.6      216.00002 ]\n",
    "#  [476.5632   189.90865 ]\n",
    "#  [473.       184.      ]\n",
    "#  [406.08005  207.36002 ]\n",
    "#  [437.94443  194.089   ]\n",
    "#  [477.6      188.40001 ]\n",
    "#  [405.6      242.40001 ]\n",
    "#  [501.12006  207.36002 ]\n",
    "#  [381.6      239.04001 ]\n",
    "#  [442.36804  167.61601 ]\n",
    "#  [426.99582  277.6966  ]\n",
    "#  [382.       203.      ]\n",
    "#  [461.       163.      ]\n",
    "#  [474.85446  184.55043 ]\n",
    "#  [454.46405  160.70401 ]\n",
    "#  [440.73135  193.49182 ]\n",
    "#  [436.80002  171.6     ]\n",
    "#  [479.52002   67.68    ]\n",
    "#  [439.60327  194.91843 ]\n",
    "#  [479.00168   64.28161 ]\n",
    "#  [474.77158  191.10303 ]\n",
    "#  [473.76     185.76001 ]\n",
    "#  [470.70728  167.96162 ]\n",
    "#  [438.00003  195.6     ]\n",
    "#  [471.6      166.8     ]\n",
    "#  [442.80002  168.      ]\n",
    "#  [482.11206  186.62402 ]\n",
    "#  [436.32     190.08    ]\n",
    "#  [443.52002  167.04001 ]\n",
    "#  [502.56003  207.36002 ]\n",
    "#  [407.52002  249.12001 ]\n",
    "#  [444.       168.      ]\n",
    "#  [406.80002  248.40001 ]]\n",
    "\n",
    "# 원근 변환 행렬 구하기 \n",
    "mtrx, mask = cv2.findHomography(src_pts, dst_pts)\n",
    "\n",
    "    # cv.findHomograpy(srcPoints, dstPoints) : 여러개의 점으로 근사 계산한 원근 변환행렬을 반환\n",
    "\n",
    "# output:\n",
    "\n",
    "# mtrx:\n",
    "\n",
    "# [[ 3.44569151e-01  1.16834400e-01  3.09253971e+02]\n",
    "#  [-3.56926367e-01  8.24989161e-01  3.57332231e+01]\n",
    "#  [-1.14522850e-03  4.55969969e-05  1.00000000e+00]]\n",
    "\n",
    "# mask:\n",
    "\n",
    "    # mask : 정상치 판별결과, N X 1행 배열 (0: 비정상치, 1: 정상치)\n",
    "\n",
    "# [[1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]\n",
    "#  [1]]\n",
    "\n",
    "\n",
    "# 원본 영상 크기로 변환 영역 좌표 생성 \n",
    "w = img2.shape[1] + img1.shape[1] # img2의 넓이 + img1의 넓이\n",
    "h = img2.shape[0] + img1.shape[0] # img2의 높이 + img1의 높이\n",
    "\n",
    "# output: { w: 960, h: 1280}\n",
    "\n",
    "# 원근 변환 적용\n",
    "dst = cv2.warpPerspective(img2, mtrx, (w, img2.shape[0]))\n",
    "\n",
    "# output: \n",
    "\n",
    "# [[[  0   0   0]\n",
    "#   [  0   0   0]\n",
    "#   [  0   0   0]\n",
    "#   ...\n",
    "#   [  8  20  33]\n",
    "#   [  7  17  31]\n",
    "#   [  5  15  28]]\n",
    "\n",
    "#  [[  0   0   0]\n",
    "#   [  0   0   0]\n",
    "#   [  0   0   0]\n",
    "#   ...\n",
    "#   [  6  16  28]\n",
    "#   [  6  15  27]\n",
    "#   [  5  15  26]]\n",
    "\n",
    "#  [[  0   0   0]\n",
    "#   [  0   0   0]\n",
    "#   [  0   0   0]\n",
    "#   ...\n",
    "#   [  6  16  26]\n",
    "#   [  6  15  25]\n",
    "#   [  6  15  24]]\n",
    "\n",
    "#  ...\n",
    "\n",
    "#  [[  0   0   0]\n",
    "#   [  0   0   0]\n",
    "#   [  0   0   0]\n",
    "#   ...\n",
    "#   [ 54  94 121]\n",
    "#   [ 51  89 117]\n",
    "#   [ 42  79 106]]\n",
    "\n",
    "#  [[  0   0   0]\n",
    "#   [  0   0   0]\n",
    "#   [  0   0   0]\n",
    "#   ...\n",
    "#   [ 51  89 114]\n",
    "#   [ 50  86 113]\n",
    "#   [ 45  79 105]]\n",
    "\n",
    "#  [[  0   0   0]\n",
    "#   [  0   0   0]\n",
    "#   [  0   0   0]\n",
    "#   ...\n",
    "#   [ 41  78  98]\n",
    "#   [ 43  78 100]\n",
    "#   [ 41  73  96]]]\n",
    "\n",
    "dst[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "\n",
    "# 결과 출력\n",
    "cv2.imshow('img1', img1)\n",
    "cv2.imshow('img2', img2)\n",
    "cv2.imshow('Good Match', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
